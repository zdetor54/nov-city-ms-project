{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path(os.getcwd()+\"\\output\\cnn_models\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input data\n",
    "\n",
    "* data: Tabular data + ground truth\n",
    "* dict_col_candidate_classes: a dictionary with filename_columns and in each of the an array of [(candidate_type, candidate_entity, original_cell_value, rank)]\n",
    "* type_neighours_pos_neg_samples: a dictionary that is used to train the classifiers so for each candidate class we have the neighbouring classes, positive samples from the KG and positive and negative samples from the tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only consider candidate classes between columns that have links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary with the lookup results for each cell value in the tabular data\n",
    "def load_json(data_json):\n",
    "    with open(data_json) as json_file:\n",
    "        return json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"output\\\\\"\n",
    "cnn_model_directory = os.getcwd()+'\\\\output\\\\cnn_models'\n",
    "\n",
    "\n",
    "data = load_json(output_folder+'data.json')\n",
    "\n",
    "dict_col_candidate_classes = load_json(output_folder+'dict_col_candidate_classes.json')\n",
    "\n",
    "\n",
    "# try:\n",
    "#     type_neighours_pos_neg_samples = load_json(output_folder+'type_neighours_pos_neg_samples.json')\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# try:\n",
    "#     dict_cand = load_json(output_folder+'dict_cand.json')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess lookup efficiency\n",
    "\n",
    "In this step, provided that we have the ground truth, we asses if the expected class is in the top x of the retrieved candidate classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, N3\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbo_sparql_results(query_string):\n",
    "    \n",
    "    classes = list([])\n",
    "    dbo_prefix = 'http://dbpedia.org/ontology/'\n",
    "    \n",
    "    \n",
    "    sparql = SPARQLWrapper('https://dbpedia.org/sparql')\n",
    "    sparql.setQuery(query_string)\n",
    "    \n",
    "    try:\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        qres = sparql.query().convert()\n",
    "        for entity_class in qres['results']['bindings']:\n",
    "            if dbo_prefix in entity_class[list(qres['results']['bindings'][0].keys())[0]]['value']:\n",
    "                candicate_class = entity_class[list(qres['results']['bindings'][0].keys())[0]]['value'].split(dbo_prefix)[1]\n",
    "                classes.append(candicate_class)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return classes\n",
    "\n",
    "def get_dbo_subclass(superClass):\n",
    "    \n",
    "    query_string = f'''\n",
    "    SELECT distinct ?subClass \n",
    "    WHERE {{ ?subClass rdfs:subClassOf dbo:{superClass}. }}\n",
    "    '''\n",
    "    return dbo_sparql_results(query_string)\n",
    "\n",
    "\n",
    "def get_dbo_superclass(subclass):\n",
    "    \n",
    "    query_string = f'''\n",
    "    SELECT distinct ?superClass \n",
    "    WHERE {{ dbo:{subclass} rdfs:subClassOf ?superClass . }}\n",
    "    '''\n",
    "    \n",
    "    return dbo_sparql_results(query_string)\n",
    "\n",
    "\n",
    "def get_dbo_superclasses(subclass):\n",
    "    classes = list([])\n",
    "    \n",
    "    try:\n",
    "        parent = get_dbo_superclass(subclass)\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    while len(parent) > 0:\n",
    "        classes.append(parent[0])\n",
    "        parent = get_dbo_superclass(parent[0])\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Athlete']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dbo_superclasses('BaseballPlayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Software',\n",
       " 'Artwork',\n",
       " 'Film',\n",
       " 'RadioProgram',\n",
       " 'TelevisionEpisode',\n",
       " 'TelevisionSeason',\n",
       " 'TelevisionShow',\n",
       " 'Website',\n",
       " 'WrittenWork',\n",
       " 'Document',\n",
       " 'MusicalWork',\n",
       " 'Database',\n",
       " 'CollectionOfValuables',\n",
       " 'LineOfFashion',\n",
       " 'قیمتی_اشیاء_کا_مجموعہ۔']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dbo_subclass('Work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_candidate_classes(dict_col_candidate_classes,filename,col,limit = -1):\n",
    "    if limit >= 0:\n",
    "        candidate_list = Counter([i[0] for i in dict_col_candidate_classes[filename][col]]).most_common()[:limit]\n",
    "    else:\n",
    "        candidate_list = Counter([i[0] for i in dict_col_candidate_classes[filename][col]]).most_common()\n",
    "#     return [x[0] for x in candidate_list]\n",
    "    return candidate_list\n",
    "\n",
    "dict_cand = dict()\n",
    "\n",
    "total = 0\n",
    "for filename in dict_col_candidate_classes:\n",
    "    dict_cand[filename] = dict()\n",
    "    for col in dict_col_candidate_classes[filename]:\n",
    "        dict_cand[filename][col] = dict()\n",
    "        dict_cand[filename][col]['class_without_hr'] = get_column_candidate_classes(dict_col_candidate_classes,filename, col)\n",
    "        total+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for filename in tqdm(dict_cand):\n",
    "    for col in dict_cand[filename]:\n",
    "        dict_cand[filename][col]['class_with_hr'] = list([])\n",
    "        for cls in dict_cand[filename][col]['class_without_hr']:\n",
    "            if len([value for value in get_dbo_subclass(cls) if value in dict_cand[filename][col]['class_without_hr']]) == 0:\n",
    "                dict_cand[filename][col]['class_with_hr'].append(cls)\n",
    "                \n",
    "with open(('output/dict_cand-%s.json' % time.strftime(\"%Y%m%d-%H%M%S\")), 'w') as fp:\n",
    "        json.dump(dict_cand, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def lookup_vote_rank_weighted(dict_col_candidate_classes,rank_threshold=1, weighted = True):\n",
    "    df_entities = pd.DataFrame()\n",
    "\n",
    "    for filename in dict_col_candidate_classes:\n",
    "        for col in dict_col_candidate_classes[filename]:\n",
    "            df_entities = df_entities.append(pd.DataFrame([[filename,col,x[0], x[1], x[2], x[3]] for x in dict_col_candidate_classes[filename][col]], columns=['filename', 'col','type', 'entity', 'cell_value', 'rank']))\n",
    "\n",
    "    df_entities = df_entities[df_entities['rank'] <= rank_threshold]\n",
    "    # temp = df_entities.groupby(by=[\"filename\", \"col\", \"type\"]).count()[\"entity\"].reset_index().sort_values(by=['filename', 'col', 'entity'],ascending=False)\n",
    "\n",
    "    df = df_entities\n",
    "    if weighted == True:\n",
    "        df['weighted_rank'] = df.apply(lambda x : 1/x['rank'], axis=1)\n",
    "    else: df['weighted_rank'] = df.apply(lambda x : 1, axis=1)\n",
    "    temp = df.groupby(by=[\"filename\", \"col\", \"type\"]).sum()[\"weighted_rank\"].reset_index().sort_values(by=['filename', 'col', 'weighted_rank'],ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dict_candidate = dict()\n",
    "    for filename in list(temp.filename.unique()):\n",
    "        dict_candidate[filename] = dict()\n",
    "        for col in list(temp[temp.filename == filename].col.unique()):\n",
    "            total = temp[(temp.filename==filename) & (temp.col == col)].sum().weighted_rank\n",
    "            df = temp[(temp.filename==filename) & (temp.col == col)].copy()\n",
    "            df['vote_pct'] = df.apply(lambda x : x.weighted_rank *100 / total, axis=1)\n",
    "            dict_candidate[filename][col] = dict()\n",
    "            dict_candidate[filename][col]['class_without_hr'] = list(df[['type','weighted_rank','vote_pct']].to_records(index=False))\n",
    "    return dict_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of having a list of all candidate classes that appear in a column, the next step is to remove classes that are higher up in the list if at least one of their subclasses also appears in the list.\n",
    "This approach seems to improve the precision (i.e. the top classes are more relevant) but decrease the recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_candidate = lookup_vote_rank_weighted(dict_col_candidate_classes,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_candidate['58891288_0_1117541047012405958']['1']['class_without_hr'][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_candidate_with_tfidf['58891288_0_1117541047012405958']['1']['class_without_hr'][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_candidate['TOUGH_WEB_MISSP_celebrities']['0']['class_without_hr'][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_candidate_with_tfidf['TOUGH_WEB_MISSP_celebrities']['0']['class_without_hr'][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(('output/dict_cand-%s.json' % time.strftime(\"%Y%m%d-%H%M%S\")), 'w') as fp:\n",
    "        json.dump(dict_candidate, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# the we increase the size of top list one element at a time until we reac the cap...\n",
    "for i in range(1,16):\n",
    "    (x,y) = (i, lookup_assessment_considering_hr(dict_candidate, i))\n",
    "    print((x,y))\n",
    "    results.append((x,y))\n",
    "\n",
    "#... and plot the results\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot([x[0] for x in results],[x[1] for x in results])\n",
    "plt.ylabel(\"Precision (%)\")\n",
    "plt.xlabel(\"Number of top x candidate classes considered\")\n",
    "plt.title(\"Lookup Voting (rank>=5)\")\n",
    "plt.axis(ymin=0, ymax=100, xmin=1, xmax=15)\n",
    "\n",
    "plt.show()\n",
    "results_top1_weighted = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results:\n",
    "    print(f\"{i[0]}:{i[1][0]} ({i[1][1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the type Agent as it is too generic and appears quite frequently\n",
    "\n",
    "for file in dict_candidate:\n",
    "    for col in dict_candidate[file]:\n",
    "        dict_candidate[file][col]['class_without_hr'] = [x for x in dict_candidate[file][col]['class_without_hr'] if x[0] != 'Agent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# the we increase the size of top list one element at a time until we reac the cap...\n",
    "for i in range(1,16):\n",
    "    (x,y) = (i, lookup_assessment_considering_hr(dict_candidate, i))\n",
    "    print((x,y))\n",
    "    results.append((x,y))\n",
    "\n",
    "#... and plot the results\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot([x[0] for x in results],[x[1] for x in results])\n",
    "plt.ylabel(\"Precision (%)\")\n",
    "plt.xlabel(\"Number of top x candidate classes considered\")\n",
    "plt.title(\"Lookup Voting (rank>=5)\")\n",
    "plt.axis(ymin=0, ymax=100, xmin=1, xmax=15)\n",
    "\n",
    "plt.show()\n",
    "results_top1_weighted = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results:\n",
    "    print(f\"{i[0]}:{i[1][0]} ({i[1][1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = list()\n",
    "\n",
    "for file in dict_candidate:\n",
    "    for col in dict_candidate[file]:\n",
    "        new.append([file,col,\"http://dbpedia.org/ontology/\"+dict_candidate[file][col]['class_without_hr'][0][0]])\n",
    "\n",
    "temp_results = pd.DataFrame(new, columns=['file','column','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_results.to_csv('lookup_rank1_pred_csv.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(('output/dict_candidate_rank1_2019-%s.json' % time.strftime(\"%Y%m%d-%H%M%S\")), 'w') as fp:\n",
    "        json.dump(dict_candidate, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for filename in tqdm(dict_cand):\n",
    "    for col in dict_cand[filename]:\n",
    "        dict_cand[filename][col]['class_with_hr'] = list([])\n",
    "        for cls in dict_cand[filename][col]['class_without_hr']:\n",
    "            if len([value for value in get_dbo_subclass(cls) if value in dict_cand[filename][col]['class_without_hr']]) == 0:\n",
    "                dict_cand[filename][col]['class_with_hr'].append(cls)\n",
    "                \n",
    "with open(('output/dict_cand-%s.json' % time.strftime(\"%Y%m%d-%H%M%S\")), 'w') as fp:\n",
    "        json.dump(dict_cand, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments:\n",
    " 1. Top X without repetition of cell values, without checking parent child relationships\n",
    " 2. Top x without repetition of cell values, having removed candidate classes for which at list one subclass also appears in the list of candidate classes\n",
    " 3. Top x with repetition of cell values. This means if a value appears multiple times in a column then the cancidate class will get more that one votes from that cell value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_assessment(dict_cand, threshold = 10000):\n",
    "    found = 0\n",
    "    found_with = 0\n",
    "    total_columns = 0\n",
    "\n",
    "    for file in dict_cand:\n",
    "        for col in dict_cand[file]:\n",
    "            candidate_class_without_hr = [x[0] for x in dict_cand[file][col]['class_without_hr'][:threshold]]\n",
    "#             candidate_class_with_hr = dict_cand[file][col]['class_with_hr'][:threshold]\n",
    "            actual_cls = data[file]['gt'][col]\n",
    "            if actual_cls in candidate_class_without_hr:\n",
    "                found+=1\n",
    "#             if actual_cls in candidate_class_with_hr:\n",
    "#                 found_with+=1\n",
    "            total_columns+=1\n",
    "    return (round(100*found/total_columns,2),round(100*found_with/total_columns,2))\n",
    "\n",
    "\n",
    "\n",
    "def lookup_assessment_considering_hr(dict_cand, threshold = 10000):\n",
    "    \"\"\"\n",
    "    This is a function that considers half a point (instead of a whole point) in case the predicted class is a parent of the expected type\n",
    "    \"\"\"\n",
    "    found = 0\n",
    "    found_with = 0\n",
    "    parent_found = 0\n",
    "    total_columns = 0\n",
    "\n",
    "    for file in dict_cand:\n",
    "        for col in dict_cand[file]:\n",
    "            candidate_class_without_hr = [x[0] for x in dict_cand[file][col]['class_without_hr'][:threshold]]\n",
    "#             candidate_class_with_hr = dict_cand[file][col]['class_with_hr'][:threshold]\n",
    "            actual_cls = data[file]['gt'][col]\n",
    "            if actual_cls in candidate_class_without_hr:\n",
    "                found+=1\n",
    "                parent_found += 1\n",
    "            # else we give half a point in case the predicted value is in the hierarchy (i.e. parent) of the actual value\n",
    "            else:\n",
    "                parents_of_expected_type = get_dbo_superclass(actual_cls)\n",
    "                intersection = [value for value in parents_of_expected_type if value in candidate_class_without_hr]\n",
    "                if len(intersection) > 0:\n",
    "                    parent_found += 0.5\n",
    "                    \n",
    "#             if actual_cls in candidate_class_with_hr:\n",
    "#                 found_with+=1\n",
    "            total_columns+=1\n",
    "    return (round(100*found/total_columns,2),round(100*parent_found/total_columns,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_candidate['58891288_0_1117541047012405958']['1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# first we calculate the max number of candidates across all the columns in the tabular data so we cap the range\n",
    "# max_cand = 0\n",
    "# for file in dict_col_candidate_classes_rank2:\n",
    "#     for col in dict_col_candidate_classes_rank2[file]:\n",
    "        \n",
    "#         candidate_cls = set()\n",
    "#         for element in dict_col_candidate_classes_rank2[file][col]:\n",
    "#             candidate_cls.add(element[0])\n",
    "#         if len(candidate_cls) > max_cand:\n",
    "#             max_cand = len(candidate_cls)\n",
    "\n",
    "# the we increase the size of top list one element at a time until we reac the cap...\n",
    "for i in range(1,16):\n",
    "    (x,y) = (i, lookup_assessment_considering_hr(dict_candidate, i))\n",
    "    results.append((x,y))\n",
    "\n",
    "#... and plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([x[0] for x in results],[x[1] for x in results])\n",
    "plt.show()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# first we calculate the max number of candidates across all the columns in the tabular data so we cap the range\n",
    "# max_cand = 0\n",
    "# for file in dict_col_candidate_classes_rank2:\n",
    "#     for col in dict_col_candidate_classes_rank2[file]:\n",
    "        \n",
    "#         candidate_cls = set()\n",
    "#         for element in dict_col_candidate_classes_rank2[file][col]:\n",
    "#             candidate_cls.add(element[0])\n",
    "#         if len(candidate_cls) > max_cand:\n",
    "#             max_cand = len(candidate_cls)\n",
    "\n",
    "# the we increase the size of top list one element at a time until we reac the cap...\n",
    "for i in range(1,26):\n",
    "    (x,y) = (i, lookup_assessment_considering_hr(dict_candidate, i))\n",
    "    results.append((x,y))\n",
    "\n",
    "#... and plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([x[0] for x in results],[x[1] for x in results])\n",
    "plt.show()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# first we calculate the max number of candidates across all the columns in the tabular data so we cap the range\n",
    "max_cand = 0\n",
    "for file in dict_col_candidate_classes_rank2:\n",
    "    for col in dict_col_candidate_classes_rank2[file]:\n",
    "        \n",
    "        candidate_cls = set()\n",
    "        for element in dict_col_candidate_classes_rank2[file][col]:\n",
    "            candidate_cls.add(element[0])\n",
    "        if len(candidate_cls) > max_cand:\n",
    "            max_cand = len(candidate_cls)\n",
    "\n",
    "# the we increase the size of top list one element at a time until we reac the cap...\n",
    "for i in range(1,16):\n",
    "    (x,y) = (i, lookup_assessment_considering_hr(dict_cand, i))\n",
    "    results.append((x,y))\n",
    "\n",
    "#... and plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([x[0] for x in results],[x[1] for x in results])\n",
    "plt.show()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# first we calculate the max number of candidates across all the columns in the tabular data so we cap the range\n",
    "max_cand = 0\n",
    "for file in dict_col_candidate_classes:\n",
    "    for col in dict_col_candidate_classes[file]:\n",
    "        \n",
    "        candidate_cls = set()\n",
    "        for element in dict_col_candidate_classes[file][col]:\n",
    "            candidate_cls.add(element[0])\n",
    "        if len(candidate_cls) > max_cand:\n",
    "            max_cand = len(candidate_cls)\n",
    "\n",
    "# the we increase the size of top list one element at a time until we reac the cap...\n",
    "for i in range(1,10):\n",
    "    (x,y) = (i, lookup_assessment(dict_cand, i))\n",
    "    results.append((x,y))\n",
    "\n",
    "#... and plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([x[0] for x in results],[x[1] for x in results])\n",
    "plt.show()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def lookup_vote_tfidf(dict_col_candidate_classes,threshold=1):\n",
    "    \n",
    "    dict_tfidf = dict()\n",
    "    cls_terms = set()\n",
    "\n",
    "    for file in dict_col_candidate_classes:\n",
    "        for col in dict_col_candidate_classes[file]:\n",
    "            key = 'file_%s_col_%s' % (file,col)\n",
    "            temp = list()\n",
    "            for cls in dict_col_candidate_classes[file][col]:\n",
    "                if cls[3] <= threshold:\n",
    "                    temp.append(cls[0])\n",
    "            cls_terms = cls_terms | set(temp)\n",
    "            dict_tfidf [key] = temp\n",
    "\n",
    "    # Calculate Term Frequency\n",
    "    dict_tf = dict()\n",
    "    for t in cls_terms:\n",
    "        dict_tf[t] = dict()\n",
    "        for document in dict_tfidf:\n",
    "            try: \n",
    "                dict_tf[t][document] = dict_tfidf[document].count(t) / len(dict_tfidf[document])\n",
    "            except:\n",
    "                dict_tf[t][document] = 0\n",
    "\n",
    "    # Calculate Inverse Document Frequency\n",
    "    dict_idf = dict()\n",
    "    for t in cls_terms:\n",
    "        count_document = 0\n",
    "        for document in dict_tfidf:\n",
    "            if dict_tfidf[document].count(t) > 0:\n",
    "                count_document +=1\n",
    "        dict_idf[t] = math.log(len(dict_tfidf)/(1+count_document))\n",
    "        \n",
    "    \n",
    "    # Bring it all together to combine tf and idf\n",
    "    dict_tf_idf_pred = dict()\n",
    "    candidates_tfidf = list()\n",
    "\n",
    "    for t in dict_tf:\n",
    "        for d in dict_tf[t]:\n",
    "            if abs(dict_tf[t][d]*dict_idf[t]) > 0:\n",
    "                candidates_tfidf.append([d[5:d.find('_col_')], d[d.find('_col_')+5:],t,dict_tf[t][d],dict_idf[t],dict_tf[t][d]*dict_idf[t]])\n",
    "                \n",
    "    # Create a dataframe with the proposed candidates\n",
    "    temp = pd.DataFrame(candidates_tfidf, columns=[\"filename\",\"column\",\"cls\",\"tf\",\"idf\",\"tfidf\"])\n",
    "    \n",
    "    #Sort the values to prep them for the assessment\n",
    "    temp.sort_values(by=[\"filename\", \"column\", \"tfidf\"], ascending=False, inplace=True)\n",
    "    \n",
    "    # and finally create the structure of the dictionary\n",
    "    dict_candidate_with_tfidf = dict()\n",
    "    for row in temp.iterrows():\n",
    "        if row[1].filename not in dict_candidate_with_tfidf:\n",
    "            dict_candidate_with_tfidf[row[1].filename] = dict()\n",
    "        if row[1].column not in dict_candidate_with_tfidf[row[1].filename]:\n",
    "            dict_candidate_with_tfidf[row[1].filename][row[1].column] = dict()\n",
    "            dict_candidate_with_tfidf[row[1].filename][row[1].column]['class_without_hr'] = list()\n",
    "\n",
    "        dict_candidate_with_tfidf[row[1].filename][row[1].column]['class_without_hr'].append((row[1].cls,row[1].tfidf))\n",
    "\n",
    "    return dict_candidate_with_tfidf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_candidate_with_tfidf = lookup_vote_tfidf(dict_col_candidate_classes,1)\n",
    "\n",
    "with open(('output/predicted_classes-%s.json' % time.strftime(\"%Y%m%d-%H%M%S\")), 'w') as fp:\n",
    "        json.dump(dict_candidate_with_tfidf, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "# dict_candidate_with_tfidf = lookup_vote_tfidf(dict_col_candidate_classes,1)\n",
    "\n",
    "# then we increase the size of top list one element at a time until we reac the cap...\n",
    "for i in range(1,16):\n",
    "    (x,y) = (i, lookup_assessment_considering_hr(dict_candidate_with_tfidf, i))\n",
    "    print(x,y)\n",
    "    results.append((x,y))\n",
    "\n",
    "#... and plot the results\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot([x[0] for x in results],[x[1] for x in results])\n",
    "plt.ylabel(\"Precision (%)\")\n",
    "plt.xlabel(\"Number of top x candidate classes considered\")\n",
    "plt.title(\"Lookup Voting (rank>=5)\")\n",
    "plt.axis(ymin=0, ymax=100, xmin=1, xmax=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results:\n",
    "    print(f\"{i[0]}:{i[1][0]} ({i[1][1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(('output/dict_cand-%s.json' % time.strftime(\"%Y%m%d-%H%M%S\")), 'w') as fp:\n",
    "        json.dump(dict_candidate_with_tfidf, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results:\n",
    "    print(f\"{i[0]}:{i[1][0]} ({i[1][1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results:\n",
    "    print(f\"{i[0]}:{i[1][0]} ({i[1][1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[(temp.filename=='29414811_6_8221428333921653560') &( temp.column=='3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tfidf = dict()\n",
    "cls_terms = set()\n",
    "threshold = 1\n",
    "\n",
    "for file in dict_col_candidate_classes:\n",
    "    for col in dict_col_candidate_classes[file]:\n",
    "        key = 'file_%s_col_%s' % (file,col)\n",
    "        temp = list()\n",
    "        for cls in dict_col_candidate_classes[file][col]:\n",
    "            if cls[3] <= threshold:\n",
    "                temp.append(cls[0])\n",
    "        cls_terms = cls_terms | set(temp)\n",
    "        dict_tfidf [key] = temp\n",
    "\n",
    "# Calculate Term Frequency\n",
    "dict_tf = dict()\n",
    "for t in cls_terms:\n",
    "    dict_tf[t] = dict()\n",
    "    for document in dict_tfidf:\n",
    "        try: \n",
    "            dict_tf[t][document] = dict_tfidf[document].count(t) / len(dict_tfidf[document])\n",
    "        except:\n",
    "            dict_tf[t][document] = 0\n",
    "\n",
    "# Calculate Inverse Document Frequency\n",
    "dict_idf = dict()\n",
    "for t in cls_terms:\n",
    "    count_document = 0\n",
    "    for document in dict_tfidf:\n",
    "        if dict_tfidf[document].count(t) > 0:\n",
    "            count_document +=1\n",
    "    dict_idf[t] = math.log(len(dict_tfidf)/(1+count_document))\n",
    "\n",
    "\n",
    "# Bring it all together to combine tf and idf\n",
    "dict_tf_idf_pred = dict()\n",
    "candidates_tfidf = list()\n",
    "\n",
    "for t in dict_tf:\n",
    "    for d in dict_tf[t]:\n",
    "        if abs(dict_tf[t][d]*dict_idf[t]) > 0:\n",
    "            candidates_tfidf.append([d[5:d.find('_col_')], d[d.find('_col_')+5:],t,dict_tf[t][d],dict_idf[t],dict_tf[t][d]*dict_idf[t]])\n",
    "\n",
    "# Create a dataframe with the proposed candidates\n",
    "temp = pd.DataFrame(candidates_tfidf, columns=[\"filename\",\"column\",\"cls\",\"tf\",\"idf\",\"tfidf\"])\n",
    "\n",
    "#Sort the values to prep them for the assessment\n",
    "temp.sort_values(by=[\"filename\", \"column\", \"tfidf\"], ascending=False, inplace=True)\n",
    "\n",
    "# and finally create the structure of the dictionary\n",
    "dict_candidate_with_tfidf = dict()\n",
    "for row in temp.iterrows():\n",
    "    if row[1].filename not in dict_candidate_with_tfidf:\n",
    "        dict_candidate_with_tfidf[row[1].filename] = dict()\n",
    "    if row[1].column not in dict_candidate_with_tfidf[row[1].filename]:\n",
    "        dict_candidate_with_tfidf[row[1].filename][row[1].column] = dict()\n",
    "        dict_candidate_with_tfidf[row[1].filename][row[1].column]['class_without_hr'] = list()\n",
    "\n",
    "    dict_candidate_with_tfidf[row[1].filename][row[1].column]['class_without_hr'].append((row[1].cls,row[1].tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
