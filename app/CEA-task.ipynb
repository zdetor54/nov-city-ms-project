{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, N3\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary with the lookup results for each cell value in the tabular data\n",
    "def load_json(data_json):\n",
    "    with open(data_json) as json_file:\n",
    "        return json.load(json_file)\n",
    "    \n",
    "def dbo_sparql_results(query_string):\n",
    "    \n",
    "    classes = list([])\n",
    "    dbo_prefix = 'http://dbpedia.org/ontology/'\n",
    "    \n",
    "    \n",
    "    sparql = SPARQLWrapper('https://dbpedia.org/sparql')\n",
    "    sparql.setQuery(query_string)\n",
    "    \n",
    "    try:\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        qres = sparql.query().convert()\n",
    "        for entity_class in qres['results']['bindings']:\n",
    "            if dbo_prefix in entity_class[list(qres['results']['bindings'][0].keys())[0]]['value']:\n",
    "                candicate_class = entity_class[list(qres['results']['bindings'][0].keys())[0]]['value'].split(dbo_prefix)[1]\n",
    "                classes.append(candicate_class)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return classes\n",
    "\n",
    "def get_dbo_subclass(superClass):\n",
    "    \n",
    "    query_string = f'''\n",
    "    SELECT distinct ?subClass \n",
    "    WHERE {{ ?subClass rdfs:subClassOf dbo:{superClass}. }}\n",
    "    '''\n",
    "    return dbo_sparql_results(query_string)\n",
    "\n",
    "\n",
    "def get_dbo_superclass(subclass):\n",
    "    \n",
    "    query_string = f'''\n",
    "    SELECT distinct ?superClass \n",
    "    WHERE {{ dbo:{subclass} rdfs:subClassOf ?superClass . }}\n",
    "    '''\n",
    "    \n",
    "    return dbo_sparql_results(query_string)\n",
    "\n",
    "\n",
    "def get_dbo_superclasses(subclass):\n",
    "    classes = list([])\n",
    "    \n",
    "    try:\n",
    "        parent = get_dbo_superclass(subclass)\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    while len(parent) > 0:\n",
    "        classes.append(parent[0])\n",
    "        parent = get_dbo_superclass(parent[0])\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load two dictionaries from a previous run:\n",
    "* the cell_values dictionary that has an instance of each cell value and the candidate entities (and their types) in descending rank of retrieval from the API\n",
    "* the predicted classes for each file / column that is a target from the CTA task\n",
    "\n",
    "We use the best version of the CTA which was the TFIDF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"output\\\\\"\n",
    "# cnn_model_directory = os.getcwd()+'\\\\output\\\\cnn_models'\n",
    "\n",
    "\n",
    "cell_values = load_json(output_folder+'cell_values.json')\n",
    "predicted_classes = load_json(output_folder+'predicted_classes.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we perform the CTA task with the following paramenters:\n",
    "* threshold is the number of predicted classes we are willin to consider for the candidate entity to be in. For instance 1 means we only consider entities in the top1 predicted types for each column from the CTA task. A threshold of 2 means we are a bit more flexible and allow entities in the top 2 predicted classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dbp_cell_entity(cell_values, threshold = 1, use_cta=True, use_hierarchy=False):\n",
    "\n",
    "    dbp_prefix = 'http://dbpedia.org/resource/'\n",
    "\n",
    "    pred_cell_value = dict()\n",
    "    \n",
    "    class_parents = dict()\n",
    "\n",
    "    for cell_value in dict(itertools.islice(cell_values.items(), 2000000)):\n",
    "    #     print(cell_values[cell_value])\n",
    "\n",
    "        #first we derive the predicted classes for the columns the cell has been found in. We can only select the top class per column or set a threshold\n",
    "        pred_cls = list()\n",
    "        for location in cell_values[cell_value]['location']:\n",
    "            for cls in predicted_classes[location[0]][str(location[1])]['class_without_hr'][:threshold]:\n",
    "                pred_cls.append(cls[0])\n",
    "        pred_cls = list(set(pred_cls))\n",
    "        \n",
    "#         print(pred_cls)       \n",
    "        if use_hierarchy == True:\n",
    "            pred_cls_with_hierarchy = list()\n",
    "            for cls in pred_cls:\n",
    "                pred_cls_with_hierarchy.append(cls)\n",
    "                \n",
    "                try:\n",
    "                    superclasses = class_parents[cls]\n",
    "                except:\n",
    "                    superclasses = get_dbo_superclasses(cls)\n",
    "                    class_parents[cls] = superclasses\n",
    "\n",
    "                for parent in superclasses:\n",
    "                    pred_cls_with_hierarchy.append(parent)\n",
    "            \n",
    "            pred_cls = list(set(pred_cls_with_hierarchy))\n",
    "#         print(pred_cls_with_hierarchy)\n",
    "\n",
    "        #next we iterate through the retrieved entities and select the first candidate entity whose class is in the candidate classes\n",
    "        for candidate_entity in cell_values[cell_value]['candidate_entities']:\n",
    "    #         print(candidate_entity, cell_values[cell_value]['candidate_entities'][candidate_entity])\n",
    "\n",
    "            # check if any of the candidate entity's classes is in the predicted classes and if so selecte that as the entity. The entities are coming ordered \n",
    "            if use_cta == True:\n",
    "                if len(list(set(pred_cls) & set(cell_values[cell_value]['candidate_entities'][candidate_entity]['candidate_classes'])))>0:\n",
    "                    pred_cell_value[cell_value] = dbp_prefix+candidate_entity\n",
    "                    break\n",
    "            else:\n",
    "                pred_cell_value[cell_value] = dbp_prefix+candidate_entity\n",
    "                break\n",
    "    return pred_cell_value\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the key \"parsed_files\" from the dictionary since it only has the list of files that have been processed to get the cell values instead of a cell value itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del cell_values[\"parsed_files\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "pred_cell_value = predict_dbp_cell_entity(cell_values, 1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://dbpedia.org/resource/Pekan_District'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cell_value['Pekan District']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With candidates selected of the set of cell values the last step is to parse the files once again and construct the output for the column results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lookup candidate entities and classes\n",
    "\"\"\"\n",
    "# import os\n",
    "import pandas as pd\n",
    "# import sys\n",
    "import argparse\n",
    "# import pyspark\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark import SparkConf, SparkContext\n",
    "# import json\n",
    "# import time\n",
    "from itertools import islice\n",
    "# from collections import Counter\n",
    "# from tqdm import tqdm\n",
    "# import re\n",
    "\n",
    "current_path = os.getcwd()\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--input_dir',\n",
    "    type=str,\n",
    "    default=os.path.join(current_path, 'data'),\n",
    "    help='Directory of input/output')\n",
    "parser.add_argument(\n",
    "    '--dataset',\n",
    "    type=str,\n",
    "#     default='round_1',\n",
    "    default='2020_2T',\n",
    "    help='The folder containing the input data')\n",
    "parser.add_argument(\n",
    "    '--target_filename',\n",
    "    type=str,\n",
    "#     default='CEA_Round1_Targets.csv',\n",
    "    default='CEA_2T_Targets.csv',    \n",
    "    help='The name of the file that contains the target types for each column')\n",
    "parser.add_argument(\n",
    "    '--gt_filename',\n",
    "    type=str,\n",
    "#     default='CEA_Round1_gt.csv',\n",
    "    default='CEA_2T_gt.csv',\n",
    "    help='The name of the file that contains the ground truth for each column')\n",
    "parser.add_argument(\n",
    "    '--file_type',\n",
    "    type=str,\n",
    "    default='csv',\n",
    "    help='File type')\n",
    "\n",
    "\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "# if not os.path.exists(FLAGS.input_dir):\n",
    "#     os.mkdir(FLAGS.input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the csv files from the input directory\n",
    "def get_data_files(data_folder):\n",
    "    \"\"\"\n",
    "    A function used to get all the csv files from the input directory\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data_folder : str\n",
    "        the folder within  the working directory where the data is located\n",
    "    \"\"\"\n",
    "\n",
    "    files = [] # a list of all filenames, including file extensions, that contain data\n",
    "    csv_files = [] # same list as above but without the file extension\n",
    "\n",
    "    # Get the list of files\n",
    "    files = [f for f in os.listdir(FLAGS.input_dir+data_folder) if os.path.isfile(os.path.join(FLAGS.input_dir+data_folder, f))]\n",
    "    csv_files = [f.replace(\".csv\",\"\") for f in os.listdir(FLAGS.input_dir+data_folder) if os.path.isfile(os.path.join(FLAGS.input_dir+data_folder, f))]\n",
    "    \n",
    "    return csv_files\n",
    "\n",
    "def get_target_cea_column_cells(target_config_file, data_folder, csv_files, filter_col = True):\n",
    "    \"\"\"\n",
    "    A function used to get which columns from the csv files need to be considered for the CTA. This is a subset of the file columns ignoring anything that is not an entity\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    target_config_file : str\n",
    "        the file that contains the target column indices for each file\n",
    "    csv_files : list\n",
    "        the list of csv files that have the tabular data\n",
    "    filter_col : boolean\n",
    "        a flag to indicate whether we should narrow down the reading of the columns to only those targeted for the CTA task\n",
    "    \"\"\"\n",
    "   \n",
    "    target_col_file = os.path.join(FLAGS.input_dir+data_folder, target_config_file)\n",
    "    df_target_col = pd.read_csv(target_col_file,header=None, names=['filename','column_index', 'cell_index'])\n",
    "    \n",
    "    # filter to only those files that are included in the csv_files\n",
    "    df_target_col = df_target_col.loc[df_target_col['filename'].isin(csv_files)]\n",
    "    \n",
    "    # collapse all rows pertaining to the same file into one key value pair. The key is the filename and the value is the list with the column indices that should be considered\n",
    "    # dict_target = {'CTRL_DBP_GEO_european_countries_capital_populated_cities': [0, 1, 2]}\n",
    "    dict_target = dict()\n",
    "    \n",
    "    for index,row in df_target_col.iterrows():\n",
    "#         print(row)\n",
    "        \n",
    "        # is this is the first row with this file create the key\n",
    "        if row['filename'] not in dict_target:\n",
    "            dict_target[row['filename']]= dict()\n",
    "        \n",
    "        if row['column_index'] not in dict_target[row['filename']]:\n",
    "            dict_target[row['filename']][row['column_index']]= list()\n",
    "        # append the new target column to the target column list for that file\n",
    "        if filter_col:\n",
    "            dict_target[row['filename']][row['column_index']].append(int(row['cell_index']))\n",
    "\n",
    "        dict_target[row['filename']][row['column_index']].sort()\n",
    "    return dict_target\n",
    "\n",
    "def get_ground_truth(file, folder, csv_files):\n",
    "    \"\"\"\n",
    "    A function used to get the ground truths as provided in the setup\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file : str\n",
    "        the file that contains the ground truth for the class of each column in each file\n",
    "    folder : str\n",
    "        the folder that contains the ground truth file\n",
    "    csv_files : list\n",
    "        the list of csv files that have the tabular data\n",
    "    \"\"\"\n",
    "    \n",
    "    dbo_prefix = 'http://dbpedia.org/ontology/'\n",
    "   \n",
    "    filepath = os.path.join(FLAGS.input_dir+folder, file)\n",
    "    df_ground_truth = pd.read_csv(filepath,header=None, names=['filename','column_index', 'cell_index', 'entity'])\n",
    "    \n",
    "    # filter to only those files that are included in the csv_files\n",
    "    df_ground_truth = df_ground_truth.loc[df_ground_truth['filename'].isin(csv_files)]\n",
    "    \n",
    "    # collapse all rows pertaining to the same file into one key value pair. The key is the filename and the value is the list with the column indices that should be considered\n",
    "    # dict_target = {'CTRL_DBP_GEO_european_countries_capital_populated_cities': [0, 1, 2]}\n",
    "    dict_gt = dict()\n",
    "    \n",
    "    for index,row in df_ground_truth.iterrows():\n",
    "        \n",
    "        # is this is the first row with this file create the key\n",
    "        if row['filename'] not in dict_gt:\n",
    "            dict_gt[row['filename']]= dict()\n",
    "        if row['column_index'] not in dict_gt[row['filename']]:\n",
    "            dict_gt[row['filename']][row['column_index']]= dict()\n",
    "        \n",
    "        dict_gt[row['filename']][row['column_index']][int(row['cell_index'])] = row['entity']\n",
    "            \n",
    "    return dict_gt\n",
    "\n",
    "def read_data(data_folder, dict_target_col, has_header_row = False):\n",
    "    \"\"\"\n",
    "    A function used to read the data from the csvs in the data_folder only considering the columns that are in the dict_target_col\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    folder : str\n",
    "        the folder that contains the csvs with the tabular data\n",
    "    dict_target_col : dictionary\n",
    "        a dictionary with csv filenames as the key and an array of relevant column indices as a value\n",
    "    has_header_row : boolean\n",
    "        a flag to indicate whether the first row in the csv files needs to be skipped as it is a header\n",
    "    \"\"\"\n",
    "    temp_list = list()\n",
    "\n",
    "    for file in dict_target_cell:\n",
    "\n",
    "        filename = file + '.' + FLAGS.file_type\n",
    "        tab_data_file = os.path.join(FLAGS.input_dir + data_folder, filename)\n",
    "        \n",
    "        df_data = pd.read_csv(tab_data_file,header=None, skiprows=[0], usecols=dict_target_col[file])\n",
    "        \n",
    "        for index,row in df_data.iterrows():\n",
    "            for col in dict_target_cell[file]:\n",
    "                if index+1 in dict_target_cell[file][col]:\n",
    "                    temp_list.append([file, col, index+1, row[col]])\n",
    "                    \n",
    "    \n",
    "    return pd.DataFrame(temp_list, columns=['filename', 'column', 'cell', 'cell_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTRL_DBP_BUS_automobile_manufacturer',\n",
       " 'CTRL_DBP_BUS_automobile_manufacturer_NOISE2',\n",
       " 'CTRL_DBP_BUS_european_company_high_revenues',\n",
       " 'CTRL_DBP_BUS_european_company_high_revenues_NOISE2',\n",
       " 'CTRL_DBP_BUS_videogame_publishers']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of csv files with tabular data\n",
    "csv_files = get_data_files('\\\\%s\\\\tables' % FLAGS.dataset)\n",
    "# csv_files = csv_files[:1]\n",
    "csv_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns we need to consider for the CTA task\n",
    "dict_target_cell = get_target_cea_column_cells(FLAGS.target_filename, '\\\\%s\\\\targets' % FLAGS.dataset, csv_files,True)\n",
    "# list(islice(dict_target_col.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = get_ground_truth(FLAGS.gt_filename, '\\\\%s\\\\gt' % FLAGS.dataset, csv_files)\n",
    "# list(islice(ground_truth.items(), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from the files and load in a dataframe with the col and cell indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('\\\\%s\\\\tables' % FLAGS.dataset, dict_target_cell,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and enrich with the prediction:\n",
    "* taking into account only entities of the suggected cta predicted class\n",
    "* selecting the top entity retrieved by the lookupg\n",
    "* selected the entity considering the cta and if no entity is in the cta classes default to the top one retieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_entity(cell_value):\n",
    "    try:\n",
    "        return pred_cell_value[cell_value]\n",
    "    except: pass\n",
    "    \n",
    "pred_cell_value = predict_dbp_cell_entity(cell_values, 1, True, True)\n",
    "data['pred_entity_with_cta'] = data.apply (lambda row: allocate_entity(row.cell_value), axis=1)\n",
    "\n",
    "pred_cell_value = predict_dbp_cell_entity(cell_values, 1, False)\n",
    "data['pred_entity_without_cta'] = data.apply (lambda row: allocate_entity(row.cell_value), axis=1)\n",
    "\n",
    "pred_cell_value = predict_dbp_cell_entity(cell_values, 1, True, False)\n",
    "data['pred_entity_with_cta_withoutpartents'] = data.apply (lambda row: allocate_entity(row.cell_value), axis=1)\n",
    "\n",
    "data['pred_entity_hybrid'] = data.apply(lambda row: row.pred_entity_with_cta if row.pred_entity_with_cta_withoutpartents is None else row.pred_entity_with_cta, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cell_value = predict_dbp_cell_entity(cell_values, 1, True, False)\n",
    "data['pred_entity_with_cta_withoutpartents'] = data.apply (lambda row: allocate_entity(row.cell_value), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_cell_value['Pekan District']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and enrich with expected result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['expected_entity'] = data.apply (lambda row: ground_truth[row.filename][row.column][row.cell], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 77.34104677542929, recall: 70.42534083922996 and f1_score: 73.72136069572677\n",
      "Precision: 81.05828480212116, recall: 72.22958882312524 and f1_score: 76.38969011049954\n",
      "Precision: 84.17090016750188, recall: 73.59791819858481 and f1_score: 78.53013148459581\n",
      "Precision: 81.05828480212116, recall: 72.22958882312524 and f1_score: 76.38969011049954\n"
     ]
    }
   ],
   "source": [
    "def evaluate_cea(data, approach):\n",
    "    total = data.shape[0]\n",
    "    total_annotated = 0\n",
    "    found = 0\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        try:\n",
    "            if row[approach] in row.expected_entity:\n",
    "                found += 1\n",
    "            total_annotated +=1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    precision = found*100 / total_annotated\n",
    "    recall = found*100 / total\n",
    "    f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return(precision, recall, f1_score)\n",
    "\n",
    "(precision, recall, f1_score) = evaluate_cea(data, 'pred_entity_without_cta')\n",
    "print(f\"Precision: {precision}, recall: {recall} and f1_score: {f1_score}\")\n",
    "\n",
    "(precision, recall, f1_score) = evaluate_cea(data, 'pred_entity_with_cta')\n",
    "print(f\"Precision: {precision}, recall: {recall} and f1_score: {f1_score}\")\n",
    "\n",
    "(precision, recall, f1_score) = evaluate_cea(data, 'pred_entity_with_cta_withoutpartents')\n",
    "print(f\"Precision: {precision}, recall: {recall} and f1_score: {f1_score}\")\n",
    "\n",
    "\n",
    "(precision, recall, f1_score) = evaluate_cea(data, 'pred_entity_hybrid')\n",
    "print(f\"Precision: {precision}, recall: {recall} and f1_score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['filename', 'column', 'cell', 'pred_entity_hybrid']].to_csv('output/cea_predictions-%s.csv' % time.strftime(\"%Y%m%d-%H%M%S\"), index = False, header = False)\n",
    "\n",
    "# ('output/cea_predictions-%s.csv' % time.strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_NaN = data.isnull()\n",
    "row_has_NaN = pd.DataFrame(is_NaN['pred_entity_without_cta']).any(axis=1)\n",
    "rows_with_NaN = data[row_has_NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_NaN = rows_with_NaN.isnull()\n",
    "row_has_both_NaN = pd.DataFrame(is_NaN['pred_entity_with_cta_withoutpartents']).any(axis=1)\n",
    "rows_with_both_NaN = data[row_has_NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59343, 9)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_both_NaN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
